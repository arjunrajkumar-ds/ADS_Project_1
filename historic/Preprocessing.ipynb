{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Guide -\n",
    "\n",
    "https://www1.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf\n",
    "\n",
    "2018 onwards uses zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_yellow = pd.read_csv('../raw_data/yellow_tripdata_2020-01.csv', encoding='utf8', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, starting out with reading csv file for a single month in the year -\n",
    "\n",
    "1. Drop all rows, for these columns:\n",
    "    VendorID\n",
    "    store_and_fwd_flag\n",
    "    extra\n",
    "    mta_tax\n",
    "    tolls_amount\n",
    "    improvement_surcharge\n",
    "    congestion_surcharge\n",
    "    \n",
    "2. Drop some rows, based on column values:\n",
    "    RatecodeID = 99\n",
    "    payment_type = 5\n",
    "    \n",
    "3. Convert obj type in dropoff / pickup to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess & filter data read in from a csv file\n",
    "\n",
    "def preprocess(df):\n",
    "    full_drop_labels = ['VendorID', 'store_and_fwd_flag', 'extra', 'mta_tax', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge']\n",
    "    df.drop(full_drop_labels, axis = 1, inplace = True)\n",
    "    df = df.loc[df['payment_type'] != 5]\n",
    "    df = df.loc[df['RatecodeID'] != 99]\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    df.dropna(subset = ['RatecodeID', 'payment_type'], inplace = True)\n",
    "    df = df.loc[(df['total_amount'] > 0) & (df['trip_distance'] > 0) & (df['total_amount'] < 500) & (df['passenger_count'] > 0)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, perform this elementary preprocessing on all month files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jan_yellow = pd.read_csv('../raw_data/yellow_tripdata_2020-01.csv', encoding='utf8', engine='python')\n",
    "feb_yellow = pd.read_csv('../raw_data/yellow_tripdata_2020-02.csv', encoding='utf8', engine='python')\n",
    "mar_yellow = pd.read_csv('../raw_data/yellow_tripdata_2020-03.csv', encoding='utf8', engine='python')\n",
    "apr_yellow = pd.read_csv('../raw_data/yellow_tripdata_2020-04.csv', encoding='utf8', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_jan = preprocess(jan_yellow)\n",
    "prep_feb = preprocess(feb_yellow)\n",
    "prep_mar = preprocess(mar_yellow)\n",
    "prep_apr = preprocess(apr_yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean dfs to feather, ready for EDA in next notebook\n",
    "\n",
    "prep_jan.reset_index().to_feather('clean_jan.feather')\n",
    "prep_feb.reset_index().to_feather('clean_feb.feather')\n",
    "prep_mar.reset_index().to_feather('clean_mar.feather')\n",
    "prep_apr.reset_index().to_feather('clean_apr.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6142038, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_jan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns\n",
    " \n",
    " Full drop VendorID, passenger_count, store_and_fwd_flag, extra, mta_tax, tolls_amount, improvement_surcharge, congestion_surcharge\n",
    " \n",
    " \n",
    " Partial drop | RatecodeID = 99 | payment_type = 5 | \n",
    "\n",
    "## Justification:\n",
    "\n",
    "*** These details will be included in the report as well, but writing out here just in case\n",
    "\n",
    "VendorID - Fully irrelevant; contains info about who provided data for the record\n",
    "\n",
    "store_and_fwd_flag - Indicates whether or not the driver had a connection to the server at the time of the trip. Interesting to note that for 'N' values, drivers could have possible artificially inflated certain metrics. However, trips with an 'N' value are relatively scarce - only 10% for January, and so don't need to be considered\n",
    "\n",
    "extra - Miscellaneous fees / charges. Currently only includes 2 possible charges, dependent on time of trip. These times are static, and specific rush hour times are provided on the TLC website. This analysis will not consider extra charges, nor their effect, and will concentrate more on the full fare amount\n",
    "\n",
    "mta_tax - See above\n",
    "\n",
    "tolls_amount - See above\n",
    "\n",
    "improvement_surcharge - See above\n",
    "\n",
    "RateCodeID - An ID of 99 corresponds to something outside of the scope of the dataset - No explanation for the 99 value was provided in the data dictionary\n",
    "\n",
    "## Dropping rows based on column value:\n",
    "\n",
    "payment_type - A value of 5 indicates an 'unknown' method of payment. This doesn't come up often; there was only 1 of these in the month of Jan\n",
    "\n",
    "## Dropping NAN values:\n",
    "Some rows contained nan values, and these were common cells between RatecodeID and payment_type. There was a tip amount attached to those instances, so the error isn't explained by a mixup with credit details. Either way, these nan rows made up less than 3% of the dataset, so they were dropped for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_yellow['store_and_fwd_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_yellow['RatecodeID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_yellow['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_drop_labels = ['VendorID', 'passenger_count', 'store_and_fwd_flag', 'extra', 'mta_tax', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "revised = jan_yellow.drop(full_drop_labels, axis = 1)\n",
    "\n",
    "print('# of columns dropped:', jan_yellow.shape[1] - revised.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = revised[(revised['payment_type'] == 5.0)].index\n",
    "revised2 = revised.drop(drop_index)\n",
    "\n",
    "print('Number of rows dropped:', revised.shape[0] - revised2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised2['RatecodeID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "revised3 = revised2.loc[revised2['RatecodeID'] != 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised3['tpep_pickup_datetime'] = pd.to_datetime(revised3['tpep_pickup_datetime'])\n",
    "revised3['tpep_dropoff_datetime'] = pd.to_datetime(revised3['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'revised3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_206/2881468932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrevised3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'revised3' is not defined"
     ]
    }
   ],
   "source": [
    "revised3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Justification -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prep_jan.describe())\n",
    "print(prep_jan.shape)\n",
    "\n",
    "# We can see that there are negative values in fare amount, trip distance, tip amount and total amount. The attributes\n",
    "# related to the fare paid are all dependent on each other, so can sort by total_amount. Negative trip distance is the\n",
    "# second issue. There were 13 entries recorded with a negative value, so draw that down to user input error.\n",
    "\n",
    "# Large values are also potential outliers - total_amount can get up to $4000 which is not realistic.\n",
    "# It appears that a general rule for NYC taxis are that they limit their trips to $500 max fare and/or 100 miles.\n",
    "# Can drop entries with a trip amount over $500.\n",
    "\n",
    "# Basic filtering too - there are a number of entries with a passenger count of 0, which obviously doesn't make sense. Could be \n",
    "# due either to input error or taxi drivers putting in fake rides to meet some sort of quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_jan = prep_jan.loc[(prep_jan['total_amount'] > 0) & (prep_jan['trip_distance'] > 0) & (prep_jan['total_amount'] < 500) & (prep_jan['passenger_count'] > 0)]\n",
    "display(prep_jan.describe())\n",
    "print(prep_jan.shape)\n",
    "\n",
    "# Still a healthy 6 mil rows after filtering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
